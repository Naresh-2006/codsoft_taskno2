# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hE-ja11Uf9yAN5IibT6kzyVS8ZKk14fE
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import plotly.express as px
import joblib
import os
import time
from pyngrok import ngrok
import subprocess

df = pd.read_csv('Churn_Modelling.csv')

def preprocess_data(df):
    df = df.copy()
    categorical_cols = ['Geography', 'Gender']
    numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']

    drop_cols = ['RowNumber', 'CustomerId', 'Surname']
    df = df.drop(columns=drop_cols, errors='ignore')
    target_col = 'Exited'
    if target_col not in df.columns:
        raise ValueError("Target column 'Exited' not found in dataset")
    encoders = {}
    for col in categorical_cols:
        if col in df.columns:
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col].astype(str))
            encoders[col] = le

    X = df.drop(columns=[target_col])
    y = df[target_col]

    scaler = StandardScaler()
    X[numerical_cols] = scaler.fit_transform(X[numerical_cols])

    return X, y, scaler, numerical_cols, categorical_cols, encoders

def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, model_name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]

    metrics = {
        'Model': model_name,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1 Score': f1_score(y_test, y_pred),
        'ROC AUC': roc_auc_score(y_test, y_prob)
    }
    return metrics, model

def kill_ngrok_processes():
    """Force kill any running ngrok processes to avoid '1 simultaneous session' error."""
    try:
        # Linux / macOS
        subprocess.run(['pkill', 'ngrok'], check=False)
    except Exception:
        pass
    try:
        # Windows
        subprocess.run(['taskkill', '/IM', 'ngrok.exe', '/F'], check=False)
    except Exception:
        pass

def main():
    X, y, scaler, numerical_cols, categorical_cols, encoders = preprocess_data(df)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    models = [
        ('Logistic Regression', LogisticRegression(random_state=42)),
        ('Random Forest', RandomForestClassifier(random_state=42)),
        ('Gradient Boosting', GradientBoostingClassifier(random_state=42))
    ]

    results = []
    trained_models = {}
    for name, model in models:
        metrics, trained_model = train_and_evaluate_model(model, X_train, X_test, y_train, y_test, name)
        results.append(metrics)
        trained_models[name] = trained_model

    results_df = pd.DataFrame(results)
    print("Model Performance Metrics:")
    print(results_df)

    best_model_name = results_df.loc[results_df['ROC AUC'].idxmax()]['Model']
    best_model = trained_models[best_model_name]
    joblib.dump(best_model, 'best_model.pkl')
    joblib.dump(scaler, 'scaler.pkl')
    joblib.dump(X.columns.tolist(), 'feature_columns.pkl')
    joblib.dump(encoders, 'encoders.pkl')

    if 'Random Forest' in trained_models:
        feature_importance = pd.DataFrame({
            'Feature': X.columns,
            'Importance': trained_models['Random Forest'].feature_importances_
        }).sort_values(by='Importance', ascending=False)
        fig = px.bar(feature_importance, x='Importance', y='Feature', title='Feature Importance (Random Forest)')
        fig.update_layout(yaxis={'categoryorder':'total ascending'})
        fig.show()

    # Write Streamlit app code to file
    streamlit_code = """
import streamlit as st
import pandas as pd
import joblib
import plotly.express as px

model = joblib.load('best_model.pkl')
scaler = joblib.load('scaler.pkl')
feature_columns = joblib.load('feature_columns.pkl')
encoders = joblib.load('encoders.pkl')

df = pd.read_csv('Churn_Modelling.csv')

st.title('Customer Churn Prediction Dashboard')
st.write('Enter customer details to predict churn probability:')

input_data = {}
for col in feature_columns:
    if col in ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']:
        input_data[col] = st.number_input(col, value=0.0, step=1.0 if col in ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary'] else 1.0, min_value=0.0)
    elif col in ['Geography', 'Gender']:
        input_data[col] = st.selectbox(col, df[col].unique())

if st.button('Predict Churn'):
    input_df = pd.DataFrame([input_data])
    for col in ['Geography', 'Gender']:
        if col in input_df.columns and col in encoders:
            try:
                input_df[col] = encoders[col].transform(input_df[col].astype(str))
            except ValueError as e:
                st.error(f"Error encoding {col}: {e}. Please select a valid option.")
                st.stop()
    numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']
    numerical_cols = [col for col in numerical_cols if col in input_df.columns]
    if numerical_cols:
        input_df[numerical_cols] = scaler.transform(input_df[numerical_cols])
    input_df = input_df[feature_columns]
    churn_prob = model.predict_proba(input_df)[:, 1][0]
    st.write(f'Churn Probability: {churn_prob:.2%}')
    if churn_prob > 0.5:
        st.error('High risk of churn!')
    else:
        st.success('Low risk of churn!')

    fig = px.pie(
        names=['Churn', 'Stay'],
        values=[churn_prob, 1-churn_prob],
        title='Churn Probability Distribution'
    )
    st.plotly_chart(fig)
"""
    with open('app.py', 'w') as f:
        f.write(streamlit_code)

    NGROK_AUTH_TOKEN = "30yEZNlDc9t3eqqkk8iraCE80qt_6SF2CKyp4wMG795iw7Jvu"
    ngrok.set_auth_token(NGROK_AUTH_TOKEN)

    kill_ngrok_processes()  # Kill any lingering ngrok processes
    ngrok.kill()
    time.sleep(2)

    public_url = ngrok.connect(8501)
    print(f"Streamlit app is running at: NgrokTunnel: \"{public_url}\" -> \"http://localhost:8501\"")

    process = subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port', '8501'])

    print("Streamlit is running in the background. Visit the ngrok URL above to access the app.")
    print("To stop the app, interrupt the kernel (Ctrl+C or Stop button in Colab).")

if __name__ == '__main__':
    main()

import pandas as pd
df = pd.read_csv('Churn_Modelling.csv')
print("Column names:", df.columns.tolist())

!pip install streamlit plotly